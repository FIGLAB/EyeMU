{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from base import *\n",
    "import sys\n",
    "from PIL import Image\n",
    "import json\n",
    "import pickle\n",
    "import socket\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "from keras.models import load_model\n",
    "\n",
    "from warp import transform_image, fvec2pose, featureize_input, get_min_pose, get_quest_fvec\n",
    "from Stitcher import Stitcher\n",
    "from SocketToUnity import OutputBroadcaster\n",
    "from WebcamVideoStream import WebcamVideoStream\n",
    "\n",
    "import tempfargs as fargs\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "sys.path.append(\"/home/bpe/VR_Controller_BPE/openpose/build/python\")\n",
    "from openpose import pyopenpose as op\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    stitcher = Stitcher()\n",
    "    broadcaster = OutputBroadcaster()\n",
    "    model = load_model('/home/bpe/VR_Controller_BPE/src/core/lift_2d_to_3d_whole_body.h5')\n",
    "    h_left = np.array([0.1625,-1.05,0])\n",
    "    h_right = np.array([-0.1625,-1.05,0])\n",
    "\n",
    "    video_fps = 0\n",
    "\n",
    "    if fargs.input_vid_no_stich:\n",
    "        single_vid = WebcamVideoStream(src=fargs.input_vid_no_stich_path, vid=True)\n",
    "        video_fps = single_vid.cap()\n",
    "    else:\n",
    "        if fargs.input_from_video:\n",
    "            rtop = WebcamVideoStream(src=fargs.rtop, vid=True)\n",
    "            rbot = WebcamVideoStream(src=fargs.rbot, vid=True)\n",
    "            ltop = WebcamVideoStream(src=fargs.ltop, vid=True)\n",
    "            lbot = WebcamVideoStream(src=fargs.lbot, vid=True)\n",
    "            video_fps = rtop.cap()\n",
    "        if fargs.input_live:\n",
    "            rtop = WebcamVideoStream(6).start()\n",
    "            rbot = WebcamVideoStream(0).start()\n",
    "            ltop = WebcamVideoStream(4).start()\n",
    "            lbot = WebcamVideoStream(2).start()\n",
    "\n",
    "    print('Initialization is done')\n",
    "\n",
    "    fshape = (1420, 730)\n",
    "    wshape = (1640, 800)\n",
    "    if fargs.outputFilePath is not None:\n",
    "        if fargs.input_vid_no_stich:\n",
    "            head, tail = os.path.split(fargs.input_vid_no_stich_path)\n",
    "            folder_name = tail.split(\".\")[0]\n",
    "        else:\n",
    "            folder_name = fargs.output_folder\n",
    "        log_path = fargs.outputFilePath + \"/\" + folder_name + \"/\"\n",
    "        video_path = fargs.outputFilePath + \"/\" + folder_name + \"/\" + folder_name + \"_output_video\"\n",
    "        video_in_path = fargs.outputFilePath + \"/\" + folder_name + \"/\" + folder_name + \"_input_video\"\n",
    "        data_log_path = fargs.outputFilePath + \"/\" + folder_name + \"/data_log/\"\n",
    "        os.makedirs(log_path, exist_ok=True)\n",
    "        if fargs.saveOutputDataLog:\n",
    "            os.makedirs(data_log_path, exist_ok=True)\n",
    "        if fargs.saveOutputVideo:\n",
    "            outvid = cv2.VideoWriter(video_path + \".avi\", cv2.VideoWriter_fourcc(*'XVID'), 10.0, fshape)\n",
    "            outvid_perspective = cv2.VideoWriter(dname + \"_vid_perspective.avi\",  cv2.VideoWriter_fourcc(*'XVID'), 10.0, fshape)\n",
    "        if fargs.saveInputVideo4cam:\n",
    "            out_inFrame = cv2.VideoWriter(video_in_path + \".avi\", cv2.VideoWriter_fourcc(*'XVID'), 10.0, (1280,960))\n",
    "            perspective_in = cv2.VideoWriter(dname + \"_vid_perspective_input.avi\",  cv2.VideoWriter_fourcc(*'XVID'), 10.0, wshape)\n",
    "\n",
    "    framecount = 0\n",
    "    params = dict()\n",
    "    params[\"model_folder\"] = \"/home/bpe/VR_Controller_BPE/openpose/models/\"\n",
    "    opWrapper = op.WrapperPython()\n",
    "    opWrapper.configure(params)\n",
    "    opWrapper.start()\n",
    "    while True:\n",
    "        start = time.time()\n",
    "\n",
    "        print(\"Received data:\", broadcaster.dataStorage[0])\n",
    "\n",
    "        if fargs.input_vid_no_stich:\n",
    "            ret, frame =  single_vid.read()\n",
    "            if not (ret):\n",
    "                print(\"Wrapping up\")\n",
    "                if fargs.outputFilePath is not None:\n",
    "                    if fargs.saveOutputVideo:\n",
    "                        outvid.release()\n",
    "                        outvid_perspective.release()\n",
    "                break\n",
    "\n",
    "            w = int(frame.shape[1]/2)\n",
    "            h = int(frame.shape[0]/2)\n",
    "            rtopf = frame[0:h,0:w]\n",
    "            ltopf = frame[0:h,w:2*w]\n",
    "            rbotf = frame[h:2*h,0:w]\n",
    "            lbotf = frame[h:2*h,w:2*w]\n",
    "        else:\n",
    "            # polling from all 4 cameras\n",
    "            ret1, rtopf = rtop.read()\n",
    "            ret2, rbotf = rbot.read()\n",
    "            ret3, ltopf = ltop.read()\n",
    "            ret4, lbotf = lbot.read()\n",
    "            if fargs.input_live:\n",
    "                rtopf = cv2.flip(rtopf, 0)\n",
    "                rbotf = cv2.flip(rbotf, 0)\n",
    "                ltopf = cv2.flip(ltopf, 0)\n",
    "                lbotf = cv2.flip(lbotf, 0)\n",
    "\n",
    "            if not (ret1 or ret2 or ret3 or ret4):\n",
    "                print(\"Wrapping up\")\n",
    "                rtop.stop()\n",
    "                rbot.stop()\n",
    "                ltop.stop()\n",
    "                lbot.stop()\n",
    "                if fargs.outputFilePath is not None:\n",
    "                    if fargs.saveOutputVideo:\n",
    "                        outvid.release()\n",
    "                        outvid_perspective.release()\n",
    "                    if fargs.saveInputVideo4cam:\n",
    "                        out_inFrame.release()\n",
    "                        perspective_in.release()\n",
    "                break\n",
    "            if not (ret1 and ret2):\n",
    "                print(\"Right not grabbed\")\n",
    "                rtopf = np.zeros((rtopf.shape[0], rtopf.shape[1], 3), np.uint8)\n",
    "                rbotf = np.zeros((rbotf.shape[0], rbotf.shape[1], 3), np.uint8)\n",
    "            if not (ret3 and ret4):\n",
    "                print(\"Left not grabbed\")\n",
    "                ltopf = np.zeros((ltopf.shape[0], ltopf.shape[1], 3), np.uint8)\n",
    "                lbotf = np.zeros((lbotf.shape[0], lbotf.shape[1], 3), np.uint8)\n",
    "\n",
    "            in_frame = np.vstack((np.hstack((rtopf,ltopf)),np.hstack((rbotf,lbotf))))\n",
    "            if fargs.saveInputVideo4cam:\n",
    "                out_inFrame.write(in_frame)\n",
    "\n",
    "        framecount = framecount + 1\n",
    "        # if framecount < 1000: continue;\n",
    "\n",
    "        lframe, rframe = stitcher.stitch(rtopf, rbotf, ltopf, lbotf)\n",
    "        pad_image = np.zeros((lframe.shape[0],20,3), np.uint8)\n",
    "        lframe = np.hstack((lframe,pad_image))\n",
    "        rframe = np.hstack((pad_image,rframe))\n",
    "        frame = np.hstack((lframe,rframe))\n",
    "\n",
    "        # OPENPOSE ON ORIGINAL STITCHING\n",
    "        datum = op.Datum()\n",
    "        datum.cvInputData = frame\n",
    "        opWrapper.emplaceAndPop(op.VectorDatum([datum]))\n",
    "        left_keypoints, right_keypoints = np.zeros((25,3)), np.zeros((25,3))\n",
    "        orig_skeletal_output = np.zeros((fshape[1], fshape[0], 3))\n",
    "        if datum.poseKeypoints is not None:\n",
    "            keypoints = np.array(datum.poseKeypoints)\n",
    "            scores = np.array(datum.poseScores)\n",
    "            idx1 = np.argmax(scores)\n",
    "            body1 = keypoints[idx1]\n",
    "            scores[idx1] = 0\n",
    "            idx2 = np.argmax(scores)\n",
    "            body2 = keypoints[idx2]\n",
    "            orig_skeletal_output = datum.cvOutputData\n",
    "            if body1[0,0] < body2[0,0]:\n",
    "                left_keypoints = body1\n",
    "                right_keypoints = body2\n",
    "            else:\n",
    "                left_keypoints = body2\n",
    "                right_keypoints = body1\n",
    "\n",
    "        right_keypoints = right_keypoints - [lframe.shape[1],0,0]\n",
    "        pose_orig = get_min_pose(left_keypoints,right_keypoints)\n",
    "\n",
    "        # USING PERSPECTIVE WARP\n",
    "        warp_lframe = transform_image(lframe,left_keypoints)\n",
    "        warp_rframe = transform_image(rframe,right_keypoints)\n",
    "        pad_image = np.zeros((warp_lframe.shape[0],20,3), np.uint8)\n",
    "        lframe = np.hstack((warp_lframe,pad_image))\n",
    "        rframe = np.hstack((pad_image,warp_rframe))\n",
    "        frame = np.hstack((lframe,rframe))\n",
    "        if fargs.saveInputVideo4cam:\n",
    "            perspective_in.write(frame)\n",
    "\n",
    "        datum = op.Datum()\n",
    "        datum.cvInputData = frame\n",
    "        opWrapper.emplaceAndPop(op.VectorDatum([datum]))\n",
    "        left_keypoints, right_keypoints = np.zeros((25,3)), np.zeros((25,3))\n",
    "        skeletal_output = np.zeros((wshape[1], wshape[0], 3))\n",
    "        if datum.poseKeypoints is not None:\n",
    "            keypoints = np.array(datum.poseKeypoints)\n",
    "            scores = np.array(datum.poseScores)\n",
    "            idx1 = np.argmax(scores)\n",
    "            body1 = keypoints[idx1]\n",
    "            scores[idx1] = 0\n",
    "            idx2 = np.argmax(scores)\n",
    "            body2 = keypoints[idx2]\n",
    "            skeletal_output = datum.cvOutputData\n",
    "            if body1[0,0] < body2[0,0]:\n",
    "                left_keypoints = body1\n",
    "                right_keypoints = body2\n",
    "            else:\n",
    "                left_keypoints = body2\n",
    "                right_keypoints = body1\n",
    "        right_keypoints = right_keypoints - [lframe.shape[1],0,0]\n",
    "        pose_persepective = get_min_pose(left_keypoints,right_keypoints)\n",
    "\n",
    "        # PROCESSING WITH CUSTOM MODEL\n",
    "        best_pose_pts = get_min_pose(pose_persepective,pose_orig)\n",
    "        fvec = featureize_input(np.array([best_pose_pts]))\n",
    "\n",
    "        if broadcaster.dataStorage[0] == \"\":\n",
    "            quest_vec = np.zeros((1,15))\n",
    "        else:\n",
    "            quest_vec = np.array([get_quest_fvec(broadcaster.dataStorage[0])])\n",
    "\n",
    "        pred = model.predict([fvec,quest_vec])\n",
    "\n",
    "        cols_to_remove = [0, 10, 12, 22, 25]\n",
    "        cols_to_remove_vals = [1.0, 0.0, -1.0, 0.0, 1.0]\n",
    "        pred = np.insert(pred, tuple([e-i for i, e in enumerate(cols_to_remove)]), 0., axis=1)\n",
    "        for k in range(len(cols_to_remove)):\n",
    "            pred[:,cols_to_remove[k]] = cols_to_remove_vals[k]\n",
    "\n",
    "        pose = fvec2pose(pred)[0]\n",
    "        print(pose.shape)\n",
    "\n",
    "        print(\"FPS: \", 1/(time.time()-start))\n",
    "\n",
    "        output_dict = {\n",
    "            \"input_live\": fargs.input_live,\n",
    "            \"prerecorded_video_fps\": video_fps,\n",
    "            \"frame_counter\": framecount,\n",
    "            \"pose_timestamp\": datetime.datetime.now().timestamp(),\n",
    "            \"combined_final_pose_smooth\": pose\n",
    "        }\n",
    "        if fargs.outputFilePath is not None:\n",
    "            if fargs.saveOutputDataLog:\n",
    "                pickle_file_out = data_log_path + str(framecount) + \".pkl\"\n",
    "                with open(pickle_file_out, 'wb') as handle:\n",
    "                    pickle.dump(output_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            if fargs.saveOutputVideo:\n",
    "                outvid.write(orig_skeletal_output)\n",
    "                outvid_perspective.write(skeletal_output)\n",
    "        if fargs.sendDatUnity:\n",
    "            broadcaster.broadcastData(output_dict)\n",
    "        if fargs.liveVisualize:\n",
    "            # cv2.imshow(\"Skeletons\", cv2.resize(orig_skeletal_output, None, fx=0.8, fy=0.8))\n",
    "            cv2.imshow(\"Skeletons with warp\", cv2.resize(skeletal_output, None, fx=0.6, fy=0.6))\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('q'):\n",
    "                print(\"Wrapping up\")\n",
    "                if fargs.input_vid_no_stich:\n",
    "                    single_vid.stop()\n",
    "                else:\n",
    "                    rtop.stop()\n",
    "                    rbot.stop()\n",
    "                    ltop.stop()\n",
    "                    lbot.stop()\n",
    "                if fargs.outputFilePath is not None:\n",
    "                    if fargs.saveOutputVideo:\n",
    "                        outvid.release()\n",
    "                        outvid_perspective.release()\n",
    "                    if fargs.saveInputVideo4cam:\n",
    "                        out_inFrame.release()\n",
    "                        perspective_in.release()\n",
    "                break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
